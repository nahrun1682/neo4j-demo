import os
import requests
from dotenv import load_dotenv
from openai import OpenAI

def get_available_models():
    """OpenAI APIã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
    api_key = os.getenv("OPENAI_API_KEY")
    
    headers = {
        "Authorization": f"Bearer {api_key}"
    }
    
    try:
        response = requests.get("https://api.openai.com/v1/models", headers=headers)
        response.raise_for_status()  # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿ
        
        models_data = response.json()
        models = [model["id"] for model in models_data["data"]]
        
        print("ğŸ¤– Available OpenAI Models:")
        for model in sorted(models):
            print(f"  - {model}")
        
        return models
    
    except requests.exceptions.RequestException as e:
        print(f"âŒ Error fetching models: {e}")
        return []

def main():
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
    load_dotenv()
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
    # available_models = get_available_models()
    # print(f'available_models: {available_models}')

    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    client = OpenAI(
        api_key=os.getenv("OPENAI_API_KEY")
    )
    
    question = """
    ã‚ãªãŸã¯ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼ä¼šå ´ã«ã„ã‚‹ã€‚
    ãƒ«ãƒ¼ã‚·ãƒ¼ã¨å¹¼å¥³ã®ä¼šè©±ãŒèã“ãˆã¦ããŸã€‚

    ã©ã†ã‚„ã‚‰ãƒ«ãƒ¼ã‚·ãƒ¼ã¯ã€Œ1ã€œ100ã€ã®ã†ã¡ã€ã„ãšã‚Œã‹ã²ã¨ã¤ã®æ•°å­—ãŒæ›¸ã‹ã‚ŒãŸç´™ã‚’ã‚‚ã£ã¦ã„ã‚‹ã‚ˆã†ã ã€‚

    ãƒ«ãƒ¼ã‚·ãƒ¼ã¯å¹¼å¥³ã«è¨€ã£ãŸã€‚

    ã€Œç§ã«æ¬¡ã®4ã¤ã®è³ªå•ã‚’ã—ã¦ã­ã€‚ãã®ç­”ãˆã§ç§ã®æŒã£ã¦ã„ã‚‹æ•°å­—ãŒåˆ†ã‹ã‚‹ã‚ˆã€

    ãƒ»ãã®æ•°å­—ã¯2ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ï¼Ÿ
    ãƒ»ãã®æ•°å­—ã¯3ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ï¼Ÿ
    ãƒ»ãã®æ•°å­—ã¯5ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ï¼Ÿ
    ãƒ»ãã®æ•°å­—ã¯7ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ï¼Ÿ

    ãƒ«ãƒ¼ã‚·ãƒ¼ã¯ã€ã€Œç§ã®æ•°å­—ã¯â—¯ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ã‚ˆã€ã¨ã„ã†ã‚ˆã†ã«4ã¤ã®è³ªå•ã®ç­”ãˆã‚’å¹¼å¥³ã«ã“ã£ãã‚Šæ•™ãˆã¦ã„ã£ãŸã€‚

    ã‚´ã‚­ã‚²ãƒ³ãªãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼å‚åŠ è€…ãŒã†ã‚‹ã•ã„ã®ã§ã€æ®‹å¿µãªãŒã‚‰ã‚ãªãŸãŒèãå–ã‚ŒãŸã®ã¯4ã¤ã®ç­”ãˆã®ã†ã¡1ã¤ã ã‘ã ã£ãŸã€‚

    ã—ã‹ã—ã€ãã‚Œã‚’èã„ã¦ã€Œãªã‚‹ã»ã©ã€‚ãã®æ•°å­—ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ã‚“ã ãªã€ã¨åˆ†ã‹ã£ãŸç¬é–“ã€ã‚ãªãŸã¯ãƒ«ãƒ¼ã‚·ãƒ¼ã®æŒã£ã¦ã„ã‚‹æ•°å­—ãŒä½•ãªã®ã‹åˆ†ã‹ã£ãŸã€‚

    ã„ã£ãŸã„ãƒ«ãƒ¼ã‚·ãƒ¼ã®æ•°å­—ã¯ä½•ã ã‚ã†ï¼Ÿ

    ãªãŠã€ãƒ«ãƒ¼ã‚·ãƒ¼ã¯ã¤ã­ã«çœŸå®Ÿã‚’èªã‚‹ã€‚
    ã¾ãŸã€ã‚ãªãŸã¯ãã‚ã‚ã¦è«–ç†çš„ãªå­˜åœ¨ã§ã‚ã‚‹ã€‚
    """
    
    print(f"Question: {question}")
    print("Answer: ", end="", flush=True)
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãƒãƒ£ãƒƒãƒˆè£œå®Œ
    stream = client.chat.completions.create(
        model="gpt-5",
        messages=[
            {"role": "user", "content": question}
        ],
        stream=True,  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
        reasoning_effort="medium"
    )
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¸€æ–‡å­—ãšã¤è¡¨ç¤º
    for chunk in stream:
        if chunk.choices[0].delta.content is not None:
            print(chunk.choices[0].delta.content, end="", flush=True)
    
    print()  # æœ€å¾Œã«æ”¹è¡Œ


if __name__ == "__main__":
    main()
